\newpage

\chapter{Experiments on Splits}
\label{chap:experimentssplits}

In this chapter we compare the ability of different heuristics in finding the values' split with lowest impurity. We are interested in choosing what heuristic/criterion to use when the exact ones don't run in reasonable time.

Our experiments are very similar to those proposed in \cite{journals/datamine/CoppersmithHH99}
except for a few details. All experiments are Monte Carlo simulations with 10,000 runs, each using a randomly-generated contingency table for the given number of values $n$ and classes $k$. Each table  was created by uniformly picking a number in $\{0, \ldots, 7\}$ for every entry. This guarantees a substantial probability of a row/column having some zero frequencies, which is common in practice. Differing from  \cite{journals/datamine/CoppersmithHH99}, if all the entries corresponding to a value or a class are zero, we re-generate the contingency table, otherwise the number of actual values and classes would not match $n$ and $k$. We evaluated Twoing, SLIQ-ext, PC-ext, LargestAlone and ListSchedule for both the Gini and Entropy impurities.



TODO: remover daqui pra baixo (ate linha)?

Table \ref{tab:Wins-Gini} and \ref{tab:wins-entropy} show, for different values of $n$ and $k$, the percentage of times that
Twoing outperformed/ was outperformed by PCext for Gini and Entropy, respectively.
Note that the percentages do not necessarily sum up $100\%$ because
there were ties.
We only show results for $k \leq 9$ because for larger values
of $k$ Twoing becomes non practical due to its running time. In addition,
we do not present results for small values of $n$ because in this
case the optimal  partition can be found reasonably quick by testing all possible partitions
so that there is no motivation for heuristics.

\begin{table}[ht]
\caption{Percentage of Wins for PCExt and Twoing for Gini impurity. At each entry the top and the bottom values
corresponds to the number of wins for Twoing and PCExt, respectively}
\begin{center}
\begin{tabular}{c|c|c|c|c}
    
		n/k & 3 & 5 & 7 & 9 \\ \hline
    \multirow{2}{*}{12 }& 8.7 & 12.0  &  13.4 & 15.0  \\ &2.4 & 0.7 & 0.1 & 0 \\ \hline
		\multirow{2}{*}{25 }&  24 & 33.6 & 38.4 & 45.1 \\ & 21.4 & 27.9 & 21.1  & 10.9 \\ \hline
		\multirow{2}{*}{50 } & 38.3  & 41.6  &  41.8 & 46.8  \\ & 37.8 & 52.4 & 54.6  & 49.9 \\
		
				%\multirow{2}{*}{12 }&X & 6\\ &Y & 2\\ & Z & 4 \\
		
		%\multirow{2}{*}{70 }&X & 3\\ &Y & 2\\ 
		
    
\end{tabular}
\end{center}
\label{tab:Wins-Gini}
\end{table}

\begin{table}[ht]
\caption{Percentage of Wins for PCExt and Twoing for Gini Entropy. At each entry the top and the bottom values
corresponds to the number of wins for Twoing and PCExt, respectively}
\begin{center}
\begin{tabular}{c|c|c|c|c}
    
		 n/k & 3 & 5 & 7 & 9 \\ \hline
    \multirow{2}{*}{12 }& 19.7 & 25.8  &  26.8 & 27.7  \\ &1.3 & 0.4 & 0.0 & 0.0 \\ \hline
		\multirow{2}{*}{25 }&  43.4 & 54.4 & 58.4 & 60.9 \\ & 12.4 & 15.8 & 12.1  & 7.0 \\ \hline
		\multirow{2}{*}{50 } & 64.6  & 70.2  &  70.0 & 69.8  \\ & 18.9 & 25.7 & 27.5  & 28.0 \\
		
				
    
\end{tabular}
\end{center}
\label{tab:wins-entropy}
\end{table}


In general, we observe an advantage of Twoing  
for both criteria, being more clear for Entropy impurity.
The maximum relative excess  between the impurities 
of the partitions found by  Twoing and PCext was $0.9\%$ for
Gini and $1.4 \%$ for Entropy.
On the other hand, the  maximum relative excess  between the impurities 
of the partitions found by  PCext and Twoing was $3.48 \%$ for
Gini and $6.23 \%$ for Entropy. 
In terms of speed, as expected, Twoing was faster up to $k=7$ and then 
PCext becomes faster.

% Although Twoing  only outperforms
% PCExt for limited number of classes we believe that this is relevant
%because one can find a number of classification tasks (e.g. UCI) 
%where the number of classes is small but larger than 2.


We do not report the results for \Alg because it was not competitive with the other
two heuristics. However, due to its running time it might be used when both $n$ and $k$ are very large and
speed is an  issue. When $n=200$ and $k=100$ $\Alg$, using one care, is almost 50 times
faster than PCExt, with the latter using  8 cores. In addition,
\Alg could be  used together with  PCExt, incurring a negligible overhead, to guarantee that the ratio 
between the impurity of the partition found and the optimal one is bounded.

 
Taking into account these  experiments, those reported in \cite{journals/datamine/CoppersmithHH99}
and the  theoretical properties of the available algorithms, 
Table  \ref{tab:guidelines}  suggests  guidelines on how to solve the 
problem of finding the binary partition of minimum impurity  in practical situation.
Of course small, medium and large depend on the available
hardware and the time one  is up to wait to train/test classification models. 


\begin{table}[htb]
\centering
\caption{Guidelines on how to solve the problem of finding the partition with minimum impurity 
in Practice.}
\label{tab:guidelines}
\begin{tabular}{c|c|c}
{\bf n} & {\bf k} & {\bf Suggested Method} \\ \hline 
small &  &  Exact \\
not small  & small & Twoing \\
not small  & not small & PC-Ext \\
\end{tabular}
\end{table}
%We are not aiming to understand which is the best availble method 




 

--------------------------------------------------------------------------



%\subsection{Small Number of Classes ($k=3$)}
The first set of experiments uses $k=3$ classes and $n=6,~12$ values. Since the Twoing criterion behaves almost perfectly, both in terms of execution time and impurity found, we don't compare it against the \Alg and ListScheduling criteria.

From tables \ref{imp-all-gini}, \ref{imp-all-infogain}, \ref{match-all-gini} and \ref{match-all-infogain}, it is striking how well Twoing performs. In almost all the simulations the impurity found is exactly the same as the exact methods. This suggests that, in cases when the exact methods don't run in reasonable time but Twoing does (that is, large $n$ and small $k$), we lose almost nothing by using it.


%\subsection{Medium Number of Classes ($k=9$)}

The second set of experiments uses $k=9$ classes and $n=6,~12$ values. The results are shown in tables \ref{imp-all-gini}, \ref{imp-all-infogain}, \ref{match-all-gini} and \ref{match-all-infogain}. The comparison between \Alg and ListScheduling is shown in tables \ref{heuristics-gini} and \ref{heuristics-infogain}.


Once again Twoing behaves remarkably well when it comes to getting the lowest impurity, but its execution time is already much larger than the criteria that use a single superclass split.


Comparing the heuristics between themselves we can see that, in terms of the Gini impurity, the \Alg heuristic is the best among them, while for the Entropy impurity, the best one is the ListScheduling method. This is consistent with the theory developed earlier in this paper.


%\subsection{Very Large Number of Values ($n\ge30$)}

The last set of experiments is focused on studying what happens when the number of values is very large ($n\ge30$) and the number of classes increases. 

First we study what happens when the number of classes is not very large ($k=3, ~9$). In this comparison we use Twoing as a baseline, since its behavior is so close to the exact methods in the other experiments and since it is still feasible to run it, while the exact methods aren't. Note that, since Twoing evaluates all the possible superclass partitions, the impurity it finds is never worse than that of \Alg and ListSchedule. The results are shown in tables \ref{imp-large1-gini}, \ref{imp-large1-infogain}, \ref{match-large1-gini}, \ref{match-large1-infogain}, \ref{heuristics-gini} and \ref{heuristics-infogain}.



Note that the results for the \Alg and the ListScheduling methods are the same when $k=3$ because they give the same superclass partitions. We can also notice that the number of times that Twoing finds a partition with impurity smaller than the other methods increases with $k$. This is explained by the exponential growth of the number of possible superclass partitions with $k$. What's surprising is that the \Alg method gives slightly better partitions than ListSchedule for the Information Gain impurity. Since both methods are within the approximation bounds set in this paper, this does not contradict our results.



In the next experiments, we use large number of values and classes. This makes both Twoing and the exact methods infeasible to be executed, so we only compare \Alg with ListSchedule. We use the minimum impurity between the two as a baseline.


\begin{table}[]
\centering
\caption{Percentage of Gini impurity above the one found by the best heuristic.}
\label{imp-large2-gini}
\begin{tabular}{l|l|l|l}
n   & k   & \Alg          & ListSchedule \\
\hline
30  & 50  & 2.82e-3\%        & 2.86e-3\% \\
50  & 30  & 3.91e-3\%        & 6.04e-3\% \\
50  & 50  & 1.72e-3\%        & 2.23e-3\% \\
50  & 100 & 0.56e-3\%        & 0.65e-3\% \\
100 & 50  & 0.72e-3\%        & 1.90e-3\% \\
100 & 100 & 0.26e-3\%        & 0.49e-3\% \\
100 & 200 & 0.09e-3\%        & 0.13e-3\% \\
200 & 100 & 0.08e-3\%        & 0.46e-3\%
\end{tabular}
\end{table}

\begin{table}[]
\centering
\caption{Percentage of Information Gain impurity above the one found by the best heuristic.}
\label{imp-large2-infogain}
\begin{tabular}{l|l|l|l}
n   & k   & \Alg & ListSchedule \\
\hline
30  & 50  & 0.02\% & 0.02\% \\
50  & 30  & 0.02\% & 0.02\% \\
50  & 50  & 0.01\% & 0.01\% \\
50  & 100 & 5.89e-3\% & 5.96e-3\% \\
100 & 50  & 4.97e-3\% & 0.01\% \\
100 & 100 & 3.02e-3\% & 5.05e-3\% \\
100 & 200 & 1.55e-3\% & 2.17e-3\% \\
200 & 100 & 0.75e-3\% & 5.66e-3\%
\end{tabular}
\end{table}

\begin{table}[]
\centering
\caption{Percentage of simulations where the Gini impurity found is worse than the one found by the best heuristic.}
\label{match-large2-gini}
\begin{tabular}{l|l|l|l}
n   & k   & \Alg & ListSchedule \\
\hline
30  & 50  & 49.71\%        & 50.22\%        \\
50  & 30  & 42.98\%        & 57.02\%        \\
50  & 50  & 46.19\%        & 53.81\%        \\
50  & 100 & 47.39\%        & 52.57\%        \\
100 & 50  & 34.74\%        & 65.26\%        \\
100 & 100 & 39.72\%        & 60.28\%        \\
100 & 200 & 43.27\%        & 56.73\%        \\
200 & 100 & 24.22\%        & 75.78\%
\end{tabular}
\end{table}



Comparing the results in tables \ref{imp-large2-gini}, \ref{imp-large2-infogain}, \ref{match-large2-gini}, \ref{match-large2-infogain}, \ref{heuristics-gini} and \ref{heuristics-infogain} we can see that, for both the Gini and Information Gain impurity measures, the \Alg is usually the best method. This is specially interesting for the Information Gain impurity, since the approximation guarantees for the method that uses a balanced superclass partition is better. Furthermore, the results for the \Alg criterion improve as the number of values and classes increase. This suggests that, in practice, one should prefer the \Alg method when $n$ and $k$ are very large, even though the approximation guarantee for the ListSchedule method is tighter.

%\subsection{Experiments Conclusions}
The above experiments strongly suggest that, when we can't run the exact criteria, the best choice we can make is to choose the Twoing criterion, if its execution time is feasible. If that's also not possible, for the Gini impurity, the best choice is always to use the \Alg criterion. For the Information Gain, we should choose between ListSchedule, if $n$ and $k$ are not significantly large, or \Alg, for larger number of values and classes.

In all the simulations the criteria satistied the approximation guarantees given in this paper. Since they all performed much better than their approximation bounds, the criterion with the best guarantee is not necessarily the best in terms of the expected impurity of the chosen partition.

