\newpage

\chapter{Experiments on Splits with Reduced Impurity}
\label{chap:experiments-splits}

In this chapter we compare the ability of different heuristics in finding the values' split with lowest impurity. We are interested in choosing what heuristic/criterion to use when the exact ones don't run in reasonable time. In the next chapter the performance of the best heuristics will be compared on real datasets against Twoing and criteria generated from our framework.

Our experiments are very similar to those proposed in \cite{journals/datamine/CoppersmithHH99} except for a few details. All experiments are Monte Carlo simulations with 10,000 runs, each using a randomly-generated contingency table for the given number of values $n$ and classes $k$. Each table  was created by uniformly picking a number in $\{0, \ldots, 7\}$ for every entry. This guarantees a substantial probability of a row/column having some zero frequencies, which is common in practice. Differing from  \cite{journals/datamine/CoppersmithHH99}, if all the entries corresponding to a value or a class are zero, we re-generate the contingency table, otherwise the number of actual values and classes would not match $n$ and $k$. We evaluated Hypercube Cover, PC-ext,
%SLIQ-ext, 
Largest Class Alone and List Scheduling for both the Gini and Entropy impurities. Note that we don't evaluate Twoing because the split selected by Hypercube Cover is always purer by construction. Moreover, it is also more natural, since we are measuring the performance of these criteria on the k-class impurity.

Tables \ref{tab:Splits-Gini} and \ref{tab:Splits-Entropy} show, for different values of $n$ and $k$, the percentage of times that
each criterion found the best Gini and Entropy impurities, respectively. Note that the percentages do not necessarily sum exactly $100\%$ since
there were ties. In these tables we only show results for $k \leq 9$ because for larger values
of $k$ Hypercube Cover becomes non-practical due to its running time. In addition, we do not present results for small values of $n$ because in this
case the optimal  partition can be found quickly by testing all possible partitions, so that there is no motivation for heuristics.

\begin{table}
\centering
\begin{tabular}{c|c|c|c|c|c} 
        n            &    k        &   HcC   &   PC-ext   &   LCA   &   LS   \\
\hline
\multirow{4}{*}{12}  &    3        &   97.3  &   91.2     &   42.8  &  42.8  \\
                     &    5        &   99.2  &   88.0     &   19.1  &  17.8  \\
                     &    7        &   99.9  &   86.6     &   11.5  &  10.8  \\
                     &    9        &   100   &   85.0     &    8.5  &   8.4  \\
\hline
\multirow{4}{*}{25}  &    3        &   73.9  &   72.7     &   24.3  &  24.3  \\
                     &    5        &   65.8  &   62.4     &    5.9  &   4.0  \\
                     &    7        &   73.3  &   58.8     &    2.0  &   1.7  \\
                     &    9        &   85.3  &   53.2     &    0.8  &   0.9  \\
\hline
\multirow{4}{*}{50}  &    3        &   51.4  &   50.6     &   16.0  &  16.0  \\
                     &    5        &   33.1  &   41.1     &    3.3  &   1.3  \\
                     &    7        &   31.0  &   40.7     &    1.0  &   0.4  \\
                     &    9        &   33.9  &   37.8     &    0.4  &   0.1
\end{tabular}
\caption{Percentage of times each criterion finds the smallest Gini impurity, compared among themselves.}
\label{tab:Splits-Gini}
\end{table}

% \begin{table}
% \tiny 
% \centering
% \begin{tabularx}{\textwidth}{c|xxxx|xxxx|xxxx} 
% \# values                       & \multicolumn{4}{c|}{12}        &  \multicolumn{4}{c|}{25}        & \multicolumn{4}{c}{50}  \\ 
% \diagbox{Criterion}{\# classes} &   3   &   5   &   7   &   9    &   3   &   5   &   7   &   9     &   3   &   5   &   7   &   9    \\
% \hline
% Hypercube Cover                 & 97.3  & 99.2  & 99.9  & 100    & 73.9  & 65.8  & 73.3  & 85.3    & 51.4  & 33.1  & 31.0  & 33.9   \\
% PC-ext                          & 91.2  & 88.0  & 86.6  & 85.0   & 72.7  & 62.4  & 58.8  & 53.2    & 50.6  & 41.1  & 40.7  & 37.8   \\
% %SLIQ-ext                        & 89.9  & 81.9  & 78.3  & 75.5   & 78.8  & 64.6  & 57.9  & 52.5    & 68.1  & 53.1  & 47.1  & 42.9   \\
% LargestClassAlone               & 42.8  & 19.1  & 11.5  &  8.5   & 24.3  &  5.9  &  2.0  &  0.8    & 16.0  &  3.3  &  1.0  &  0.4   \\
% ListScheduling                  & 42.8  & 17.8  & 10.8  &  8.4   & 24.3  &  4.0  &  1.7  &  0.9    & 16.0  &  1.3  &  0.4  &  0.1 
% \end{tabularx}
% \normalsize
% \caption{Percentage of times each criterion finds the smallest Gini impurity, compared among themselves.}
% \label{tab:Splits-Gini}
% \end{table}


\begin{table}
\centering
\begin{tabular}{c|c|c|c|c|c} 
        n            &    k        &   HcC   &   PC-ext   &   LCA   &   LS   \\
\hline
\multirow{4}{*}{12}  &    3        &   98.3  &   80.2     &   33.5  &  33.5  \\
                     &    5        &   99.4  &   74.2     &   13.6  &  15.3  \\
                     &    7        &   100   &   73.2     &    8.3  &  10.1  \\
                     &    9        &   100   &   72.4     &    6.8  &   8.0  \\
\hline
\multirow{4}{*}{25}  &    3        &   83.3  &   54.4     &   18.5  &  18.5  \\
                     &    5        &   76.9  &   42.7     &    5.3  &   2.6  \\
                     &    7        &   81.0  &   39.2     &    2.0  &   1.2  \\
                     &    9        &   87.7  &   37.7     &    1.3  &   0.8  \\
\hline
\multirow{4}{*}{50}  &    3        &   70.0  &   29.5     &   13.4  &  13.4  \\
                     &    5        &   57.4  &   22.0     &    3.7  &   0.6  \\
                     &    7        &   53.5  &   21.7     &    1.6  &   0.1  \\
                     &    9        &   52.5  &   22.1     &    0.8  &   0.1
\end{tabular}
\caption{Percentage of times each criterion finds the smallest Entropy impurity, compared among themselves.}
\label{tab:Splits-Entropy}
\end{table}


% \begin{table}
% \tiny 
% \centering
% \begin{tabularx}{\textwidth}{c|xxxx|xxxx|xxxx} 
% \# values                       & \multicolumn{4}{c|}{12}        &  \multicolumn{4}{c|}{25}        & \multicolumn{4}{c}{50}  \\ 
% \diagbox{Criterion}{\# classes} &   3   &   5   &   7   &   9    &   3   &   5   &   7   &   9     &   3   &   5   &   7   &   9    \\
% \hline
% Hypercube Cover                 & 98.3  & 99.4  & 100   & 100    & 83.3  & 76.9  & 81.0  & 87.7    & 70.0  & 57.4  & 53.5  & 52.5   \\
% PC-ext                          & 80.2  & 74.2  & 73.2  & 72.4   & 54.4  & 42.7  & 39.2  & 37.7    & 29.5  & 22.0  & 21.7  & 22.1   \\
% %SLIQ-ext                        & 87.5  & 78.2  & 75.2  & 72.8   & 71.8  & 57.1  & 52.1  & 47.1    & 55.1  & 42.5  & 38.8  & 36.2   \\
% LargestClassAlone               & 33.5  & 13.6  &  8.3  &  6.8   & 18.5  &  5.3  &  2.0  &  1.3    & 13.4  &  3.7  &  1.6  &  0.8   \\
% ListScheduling                  & 33.5  & 15.3  & 10.1  &  8.0   & 18.5  &  2.6  &  1.2  &  0.8    & 13.4  &  0.6  &  0.1  &  0.1 
% \end{tabularx}
% \normalsize
% \caption{Percentage of times each criterion finds the smallest Entropy impurity, compared among themselves.}
% \label{tab:Splits-Entropy}
% \end{table}

In general, we observe an advantage for Hypercube Cover with both impurities, being more clear for the Entropy, followed by PC-ext. This suggests that the Largest Class Alone and List Scheduling heuristics are not competitive with them in terms of split impurity found.

Another possible comparison between them is to see what happens when Hypercube Cover and PC-ext find different partitions. To measure this difference, let us define the relative excess (in percentage) of a partition P w.r.t. a partition Q as $100 \times (I(P)/I(Q) - 1)$. The results of this measurement are shown in Tables \ref{tab:Relative-Excess-Gini} and \ref{tab:Relative-Excess-Entropy}. For the Gini impurity (Table \ref{tab:Relative-Excess-Gini}), we can observe that Hypercube Cover finds partitions closer to the optimal than PC-ext. This behavior is even stronger for the Entropy impurity (Table \ref{tab:Relative-Excess-Entropy}), where both the average and maximum relative excess of Hypercube Cover over PC-ext is much smaller than PC-ext's over Hypercube Cover. These numbers suggest that the risk of finding a ``bad'' partition is smaller when Hypercube Cover is used, specially for the Entropy impurity.

\begin{table}
\centering
\begin{tabular}{c|c|c|c|c|c} 
\multirow{2}{*}{n}   & \multirow{2}{*}{k}  &   \multicolumn{2}{c|}{HcC excess over PC-ext} &  \multicolumn{2}{c}{PC-ext excess over HcC}   \\
                     &                     &   Average           &    Max                  &   Average           &    Max                  \\
\hline
\multirow{4}{*}{12}  &    3                &   0.15              &   0.97                  &   0.37              &  2.36                   \\
                     &    5                &   0.06              &   0.22                  &   0.14              &  0.98                   \\
                     &    7                &   0.02              &   0.05                  &   0.08              &  0.49                   \\
                     &    9                &   ---               &   ---                   &   0.05              &  0.36                   \\
\hline
\multirow{4}{*}{25}  &    3                &   0.14              &   0.83                  &   0.24              &  1.72                   \\
                     &    5                &   0.05              &   0.29                  &   0.1               &  0.84                   \\
                     &    7                &   0.32              &   1.84                  &   0.32              &  1.62                   \\
                     &    9                &   0.19              &   1.06                  &   0.2               &  1.16                   \\
\hline
\multirow{4}{*}{50}  &    3                &   1.35              &   7.27                  &   1.37              &  8.66                   \\
                     &    5                &   0.39              &   2.02                  &   0.38              &  2.1                    \\
                     &    7                &   0.19              &   0.95                  &   0.18              &  1.11                   \\
                     &    9                &   0.11              &   0.62                  &   0.11              &  0.53
\end{tabular}
\caption{Relative excess impurity, in percentage, for experiments where Hypercube Cover and PC-ext found different partitions using the Gini impurity.}
\label{tab:Relative-Excess-Gini}
\end{table}


\begin{table}
\centering
\begin{tabular}{c|c|c|c|c|c} 
\multirow{2}{*}{n}   & \multirow{2}{*}{k}  &   \multicolumn{2}{c|}{HcC excess over PC-ext} &  \multicolumn{2}{c}{PC-ext excess over HcC}   \\
                     &                     &   Average           &    Max                  &   Average           &    Max                  \\
\hline
\multirow{4}{*}{12}  &    3                &   0.17              &   1.07                  &   0.77              &  6.59                   \\
                     &    5                &   0.09              &   0.39                  &   0.37              &  2.64                   \\
                     &    7                &   0.04              &   0.04                  &   0.24              &  2.11                   \\
                     &    9                &   ---               &   ---                   &   0.18              &  1.42                   \\
\hline
\multirow{4}{*}{25}  &    3                &   0.14              &   0.81                  &   0.5               &  4.26                   \\
                     &    5                &   0.08              &   0.49                  &   0.26              &  2.02                   \\
                     &    7                &   0.53              &   3.23                  &   0.58              &  3.12                   \\
                     &    9                &   0.38              &   2.11                  &   0.42              &  2.31                   \\
\hline
\multirow{4}{*}{50}  &    3                &   1.33              &   7.87                  &   1.46              &  7.31                   \\
                     &    5                &   0.5               &   2.69                  &   0.58              &  3.07                   \\
                     &    7                &   0.29              &   1.5                   &   0.35              &  1.85                   \\
                     &    9                &   0.21              &   1.2                   &   0.25              &  1.25
\end{tabular}
\caption{Relative excess impurity, in percentage, for experiments where Hypercube Cover and PC-ext found different partitions using the Entropy impurity.}
\label{tab:Relative-Excess-Entropy}
\end{table}


Lastly, we note that, due to Largest Class Alone and List Scheduling running times, they might be used when both $n$ and $k$ are very large and speed is an  issue. When $n=200$ and $k=100$, using a single core, they are almost 50 times faster than PC-ext, with the latter using 8 cores. In addition, they could be  used together with PC-ext, incurring a negligible overhead, to guarantee that the ratio between the impurity of the partition found and the optimal one is bounded.

 
Taking into account these  experiments, those reported in \cite{journals/datamine/CoppersmithHH99} and the  theoretical properties of the available algorithms, Table \ref{tab:guidelines}  suggests  guidelines on which criterion to use to solve the problem of finding the binary partition of minimum impurity in practical situation. Of course small, medium and large depend on the available hardware and the time one accepts to wait for training/testing classification models. 


\begin{table}[htb]
\centering
\begin{tabular}{c|c|c}
{\bf n}    & {\bf k}   & {\bf Suggested Method} \\ \hline 
small      & any       &  Exact \\
not small  & small     &  Hypercube Cover \\
not small  & not small &  PC-ext \\
\end{tabular}
\caption{Guidelines on how to solve the problem of finding the partition with minimum impurity in practice.}
\label{tab:guidelines}
\end{table}

